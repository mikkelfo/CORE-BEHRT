train_encoded: 'train_encoded.pt'
val_encoded: 'val_encoded.pt'
vocabulary: 'vocabulary.pt'
checkpoint: 'pretrained_model.pt'

model:
  max_position_embeddings: 512
  linear: true
  hidden_size: 192
  num_hidden_layers: 6
  num_attention_heads: 6
  intermediate_size: 64

optimizer:
  lr: 3e-4
  weight_decay: 0
  epsilon: 1e-6
x
trainer_args:
  batch_size: 32
  effective_batch_size: 512
  epochs: 10
  info: true

metrics:
  top1:
    _target_: evaluation.metrics.top_k
    _partial_: true
    topk: 1
  top10:
    _target_: evaluation.metrics.top_k
    _partial_: true
    topk: 10
  top30:
    _target_: evaluation.metrics.top_k
    _partial_: true
    topk: 30
  top50:
    _target_: evaluation.metrics.top_k
    _partial_: true
    topk: 50
  top100:
    _target_: evaluation.metrics.top_k
    _partial_: true
    topk: 100
